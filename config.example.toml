# Example configuration file for Redline application

# Connection settings for main chain and ephemeral URLs
[connection]
# URL of the chain node to connect to
chain-url = "http://api.devnet.solana.com"
# URL of the ephemeral node to connect to
ephem-url = "http://127.0.0.1:8899"
# Type of HTTP connection: "http1" or "http2"
http-connection-type = "http2"
# Maximum number of HTTP connections
http-connections-count = 16
# Maximum number of WebSocket connections
ws-connections-count = 16

# Benchmark settings
[benchmark]
# Number of iterations for the benchmark
iterations = 100000
# The desired throughput for transaction submission to the target ER node,
# expressed in transactions per second. 
# Note: This serves as a hint rather than a strict limit. For instance,
# specifying a rate of 10,000 TPS while the ER node's transaction ingestion
# rate is 3,000 TPS will not increase the validator's capacity to handle the
# specified throughput. Consequently, any value exceeding the validator's
# saturation point is ineffective.
tps = 3000
# Number of concurrent executions
concurrency = 64
# Perform a preflight check for each transaction: true or false
preflight-check = false

# Inidicates how many concurrent benchmarks to run
# 
# NOTE: each provided unit of parallelism will start its own thread of
# execution for benchmark, dramatically increasing the load on target
# validator. I.e. each benchmark will run in parallel with others on their own
# OS thread, so for example providing 10 for parallelism, has 10x load in
# comparison to 1. This might negatively affect validator performance running
# on the same host as the REDLINE will compete for compute resources with
# validator process
parallelism = 1

# Mode of benchmark, options:
mode = "simple-byte-set"

# Alternative modes are:
#--------------------------------------------------------------------------------
#--------------------------------------------------------------------------------
# every clone-frequency-secs, and airdrop will be performed on of the readonly
# accounts on chain, thus triggering clone of account on ER 

# mode = { "trigger-clones" = { clone-frequency-secs = 1, accounts-count = 16 } }

#--------------------------------------------------------------------------------
# performs an expensive hash compute in loop (iters times), 28 iterations
# consume almost the entirety of 200K CUs

# mode = { "high-cu-cost" = { iters = 8 } }

#--------------------------------------------------------------------------------
# performs data copy operation between accounts in the pool, each transaction
# involves 2 accounts, one readable, one writable, thus high number of
# transactions using intersecting set of accounts will create pressure on
# scheduler due to account locking

# mode = { "read-write" = { accounts-pool-size = 32 } }

#--------------------------------------------------------------------------------
# a combination of various benchmarking modes, to simulate more real world scenarios

# mode = { "mixed" = [ { "simple-byte-set" }, { "high-cu-cost" = { iters = 28 } } ] }

[subscription]
# Subscription settings
# Whether to subscribe to account notifications: true or false
subscribe-to-accounts = true
# Whether to subscribe to signature notifications: true or false
subscribe-to-signatures = true
# Enforce total synchronization: true or false
# this ensures that a transaction is considered completed only if account
# update and signature update has been received, while preventing other
# transactions from running, thus significantly decreasinng throughput.
# If disabled, transaction will reserve concurrency slot only for as long as
# it's required to receive HTTP response
enforce-total-sync = true

[data]
# Data settings for account encoding and size
# Encoding type of the account data: "base58", "base64", "base64+zstd"
account-encoding = "base64+zstd"
# Size of the account data: bytes128, bytes512, bytes2048, bytes8192
account-size = "bytes128"
